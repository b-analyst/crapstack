{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from crapstack.document_stores.faiss import FAISSDocumentStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = FAISSDocumentStore(embedding_dim=128, faiss_index_factory_str=\"Flat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>mainclass_id</th>\n",
       "      <th>year</th>\n",
       "      <th>patent_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3930300</td>\n",
       "      <td>257</td>\n",
       "      <td>1976</td>\n",
       "      <td>Junction field effect transistor  A junction f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3930303</td>\n",
       "      <td>257</td>\n",
       "      <td>1976</td>\n",
       "      <td>Method manufacturing compact thermoelectric mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3930304</td>\n",
       "      <td>257</td>\n",
       "      <td>1976</td>\n",
       "      <td>Method apparatus selective burnout trimming in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3930305</td>\n",
       "      <td>257</td>\n",
       "      <td>1976</td>\n",
       "      <td>Method manufacturing integrated circuits A met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3930306</td>\n",
       "      <td>257</td>\n",
       "      <td>1976</td>\n",
       "      <td>Process attaching lead member semiconductor de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814692</th>\n",
       "      <td>8496534</td>\n",
       "      <td>470</td>\n",
       "      <td>2013</td>\n",
       "      <td>Group taps prepared hole cutting tools In FIG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814693</th>\n",
       "      <td>8534022</td>\n",
       "      <td>470</td>\n",
       "      <td>2013</td>\n",
       "      <td>Twisted threaded reinforcing bar Techniques re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814694</th>\n",
       "      <td>8550755</td>\n",
       "      <td>470</td>\n",
       "      <td>2013</td>\n",
       "      <td>Tap driver rigidsynchronous tapping Disclosed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814695</th>\n",
       "      <td>8602696</td>\n",
       "      <td>470</td>\n",
       "      <td>2013</td>\n",
       "      <td>Form tap plurality lobes A form tap tapping ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814696</th>\n",
       "      <td>8616039</td>\n",
       "      <td>470</td>\n",
       "      <td>2013</td>\n",
       "      <td>Method manufacturing clinch pin fastener A cli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7814697 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         patent_id  mainclass_id  year  \\\n",
       "0          3930300           257  1976   \n",
       "1          3930303           257  1976   \n",
       "2          3930304           257  1976   \n",
       "3          3930305           257  1976   \n",
       "4          3930306           257  1976   \n",
       "...            ...           ...   ...   \n",
       "7814692    8496534           470  2013   \n",
       "7814693    8534022           470  2013   \n",
       "7814694    8550755           470  2013   \n",
       "7814695    8602696           470  2013   \n",
       "7814696    8616039           470  2013   \n",
       "\n",
       "                                               patent_text  \n",
       "0        Junction field effect transistor  A junction f...  \n",
       "1        Method manufacturing compact thermoelectric mo...  \n",
       "2        Method apparatus selective burnout trimming in...  \n",
       "3        Method manufacturing integrated circuits A met...  \n",
       "4        Process attaching lead member semiconductor de...  \n",
       "...                                                    ...  \n",
       "7814692  Group taps prepared hole cutting tools In FIG ...  \n",
       "7814693  Twisted threaded reinforcing bar Techniques re...  \n",
       "7814694  Tap driver rigidsynchronous tapping Disclosed ...  \n",
       "7814695  Form tap plurality lobes A form tap tapping ar...  \n",
       "7814696  Method manufacturing clinch pin fastener A cli...  \n",
       "\n",
       "[7814697 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('c:/users/kchun/desktop/notebooks/patents_v6.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:05, 1802.50it/s]            \n"
     ]
    }
   ],
   "source": [
    "from crapstack.haystack.schema import Document\n",
    "\n",
    "documents = [Document(content=txt) for txt in data['patent_text'].sample(frac=.0005)]\n",
    "document_store.write_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "ML logging didn't work: name 'tracker' is not defined\n"
     ]
    }
   ],
   "source": [
    "from crapstack.haystack.nodes.retriever import DensePassageRetriever\n",
    "from crapstack.haystack.nodes.answer_generator.transformers import Seq2SeqGenerator\n",
    "from crapstack.haystack.pipelines.standard_pipelines import GenerativeQAPipeline\n",
    "# from transformers import T5ForConditionalGeneration\n",
    "# import torch\n",
    "\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"vblagoje/dpr-question_encoder-single-lfqa-wiki\",\n",
    "    passage_embedding_model=\"vblagoje/dpr-ctx_encoder-single-lfqa-wiki\",\n",
    ")\n",
    "\n",
    "generator = Seq2SeqGenerator(model_name_or_path=\"vblagoje/bart_lfqa\")\n",
    "# generator = T5ForConditionalGeneration.from_pretrained(\"google/flan-ul2\", torch_dtype=torch.bfloat16, device_map=\"auto\")                                                                 \n",
    "\n",
    "pipe = GenerativeQAPipeline(generator, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Documents Processed: 10000 docs [15:08, 11.01 docs/s]           \n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is machine learning?',\n",
       " 'answers': [<Answer {'answer': \"Machine learning is the process of training a neural network to recognize patterns in data. For example, let's say you want to train a computer to recognize faces in pictures. You have a bunch of pictures of faces, and you want the computer to be able to recognize the faces. You give the computer a picture of a face, and it looks at the pictures and tries to figure out what the face looks like. You then give it another picture of the same face and it does the same thing, and so on. Machine learning is a way of teaching a computer how to recognise faces.\", 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['d0cf790b5e9880fb4caa647b7ff55fd6', 'c614b1b24441ba6ae044a23fd40a4681', '9f194f13ccb811c3c34cd662bf9f262d', 'e71aeadb00daaa25d07c3d506c7cf9d4', 'cc42c1df9b4afa058ecfb69c2715b9be', 'c2ef8a6a81a76b9b84de55da638d2d84', 'a8a8e51de24d39f9ae17ddeca71303b', 'd26cc53dbe5aace08fac5a6515220bf6', '808d28cac4e6a9a5a7704fa04c34f1da', 'ad4f5a3fc838db6153e9de1beb6ea7bf'], 'meta': {'doc_scores': [0.5362377583968502, 0.5352674678762634, 0.5329761519729421, 0.5325924741477306, 0.531971872132457, 0.5311779177421433, 0.5311626066326977, 0.5286737698224112, 0.5283082893181298, 0.5282232177480873], 'content': ['Runtime customization objectoriented design A runtime customization capability extends functionality software application computer system Through objectoriented design instance first class instantiated The first class eg derived class interface second class The first second classes enable respective first second functionalities respective first second implementations interface The first implementation dynamically loaded run time The dynamic loading involve locating first implementation using locator locate module comprising first implementation A transfer vector usable accessing first implementation initialized indication location first implementation Programming code associated interface compiled prior compilation programming code associated first implementation', 'Method apparatus suspending software virtual machine A computer system includes software virtual machine such Java running one applications An object provided responsive call application placing virtual machine application state suspension This involves interrupting current threads recording state components virtual machine including heap threads stack serialization data structure Subsequently serialization data structure invoked resume virtual machine application state suspension Note many virtual machines cloned single stored data structure One benefit approach new virtual machine effectively created already initialized state', 'Method apparatus training neural network learn use fidelity metric control mechanism A signal processing apparatus concomitant method learning using fidelity metric control mechanism process large quantities fidelity metrics visual discrimination measure VDM manageable subjective image quality ratings The signal processing apparatus incorporates VDM neural network The VDM receives input image sequences generates fidelity metrics received neural network The neural network trained learn use fidelity metrics control mechanism eg control video encoder', 'Systems methods debugging application running parallelprocessing computer system A runtime system implemented accordance present invention provides application platform parallelprocessing computer systems Such runtime system enables users leverage computational power parallelprocessing computer systems accelerateoptimize numeric arrayintensive computations application programs This enables greatly increased performance highperformance computing HPC applications', 'Method apparatus efficiently accounting temporal nature audio processing Some embodiments invention provide computer system processing audio track This system includes least one DSP processing audio track It also includes application editing audio track To process audio data first interval audio track application first asks obtains DSP impulse response parameter related DSPs processing audio data From received impulse response parameter application identifies second audiotrack interval first interval To process audio data first interval application directs DSP process audio data within first second intervals', 'Computer program methods automatically initializing audio controller A computer program type commonly known wizard disclosed initializes user interface software controlling audio conferencing device The wizard allows desired audio inputs eg microphone telephones etc audio outputs speakers recording devices etc chosen audio system administrator Thereafter wizard allows audio conferencing device or devices chosen administrator allows devices optimally chosen dependent upon chosen inputs outputs The wizard maps inputs outputs input output ports audio conferencing device When administrator finishes wizard wizard computes mapping parameters audiooptimizing parameters selected inputs outputs These parameters loaded user interface software automatically', 'Method apparatus facilitating communication virtual machines A computerimplemented method apparatus virtual machine facilitating communication VMs The method facilitating communication first VM second VM includes allocating shared memory segment within memory physical machine mapping requested memory space addresses shared memory segments response memory space requests VMs providing requested memory space addresses A method communication first VM second VM includes requesting memory space response notification shared memory segment allocated obtaining requested memory space address mapped allocated shared memory segment accessing communication data shared memory segment according address The apparatus virtual machine executes steps methods', 'Information management tracking system IMTS An information management tracking system manages tracks artifact data relating development process artifact data including data relating development experiment parameters results products The system includes data management component process design environment retaining data relating process design A development tracking environment retains data relating process development including artifacts A back annotation environment receives process data provides development tracking environment The data management component arranged control process design environment development tracking environment back annotation environment that use data received stored therein accessed linked manner that use user obtain data environment view links between', 'Heterotopias cyberspace module In present invention users Internet share accumulate experiences referencing different uses experience data', 'High speed nonvolatile memory device using parallel writing among plurality interfaces Described high speed nonvolatile memory device technology includes controller coupled via interfaces sets nonvolatile storage separate flash memory chips separate regions single chip The controller includes logic processes write requests arbitrary size interleaving writes among interfaces including parallel writing among interfaces For example data may received via direct memory access DMA transfers The controller maintains information allow interleaved data reassembled correct relative locations read back DMA The high speed nonvolatile memory device thus provides hardware device software solution allows personal computer rapidly boot resume reduced power state hibernation The high speed nonvolatile memory device also may used data storage purposes caching file storage'], 'titles': ['', '', '', '', '', '', '', '', '', ''], 'doc_metas': [{'vector_id': '3153'}, {'vector_id': '2984'}, {'vector_id': '2341'}, {'vector_id': '3522'}, {'vector_id': '3083'}, {'vector_id': '2929'}, {'vector_id': '2501'}, {'vector_id': '3188'}, {'vector_id': '1839'}, {'vector_id': '2585'}]}}>],\n",
       " 'documents': [<Document: {'content': 'Runtime customization objectoriented design A runtime customization capability extends functionality software application computer system Through objectoriented design instance first class instantiated The first class eg derived class interface second class The first second classes enable respective first second functionalities respective first second implementations interface The first implementation dynamically loaded run time The dynamic loading involve locating first implementation using locator locate module comprising first implementation A transfer vector usable accessing first implementation initialized indication location first implementation Programming code associated interface compiled prior compilation programming code associated first implementation', 'content_type': 'text', 'score': 0.5362377583968502, 'meta': {'vector_id': '3153'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd0cf790b5e9880fb4caa647b7ff55fd6'}>,\n",
       "  <Document: {'content': 'Method apparatus suspending software virtual machine A computer system includes software virtual machine such Java running one applications An object provided responsive call application placing virtual machine application state suspension This involves interrupting current threads recording state components virtual machine including heap threads stack serialization data structure Subsequently serialization data structure invoked resume virtual machine application state suspension Note many virtual machines cloned single stored data structure One benefit approach new virtual machine effectively created already initialized state', 'content_type': 'text', 'score': 0.5352674678762634, 'meta': {'vector_id': '2984'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c614b1b24441ba6ae044a23fd40a4681'}>,\n",
       "  <Document: {'content': 'Method apparatus training neural network learn use fidelity metric control mechanism A signal processing apparatus concomitant method learning using fidelity metric control mechanism process large quantities fidelity metrics visual discrimination measure VDM manageable subjective image quality ratings The signal processing apparatus incorporates VDM neural network The VDM receives input image sequences generates fidelity metrics received neural network The neural network trained learn use fidelity metrics control mechanism eg control video encoder', 'content_type': 'text', 'score': 0.5329761519729421, 'meta': {'vector_id': '2341'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '9f194f13ccb811c3c34cd662bf9f262d'}>,\n",
       "  <Document: {'content': 'Systems methods debugging application running parallelprocessing computer system A runtime system implemented accordance present invention provides application platform parallelprocessing computer systems Such runtime system enables users leverage computational power parallelprocessing computer systems accelerateoptimize numeric arrayintensive computations application programs This enables greatly increased performance highperformance computing HPC applications', 'content_type': 'text', 'score': 0.5325924741477306, 'meta': {'vector_id': '3522'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'e71aeadb00daaa25d07c3d506c7cf9d4'}>,\n",
       "  <Document: {'content': 'Method apparatus efficiently accounting temporal nature audio processing Some embodiments invention provide computer system processing audio track This system includes least one DSP processing audio track It also includes application editing audio track To process audio data first interval audio track application first asks obtains DSP impulse response parameter related DSPs processing audio data From received impulse response parameter application identifies second audiotrack interval first interval To process audio data first interval application directs DSP process audio data within first second intervals', 'content_type': 'text', 'score': 0.531971872132457, 'meta': {'vector_id': '3083'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'cc42c1df9b4afa058ecfb69c2715b9be'}>,\n",
       "  <Document: {'content': 'Computer program methods automatically initializing audio controller A computer program type commonly known wizard disclosed initializes user interface software controlling audio conferencing device The wizard allows desired audio inputs eg microphone telephones etc audio outputs speakers recording devices etc chosen audio system administrator Thereafter wizard allows audio conferencing device or devices chosen administrator allows devices optimally chosen dependent upon chosen inputs outputs The wizard maps inputs outputs input output ports audio conferencing device When administrator finishes wizard wizard computes mapping parameters audiooptimizing parameters selected inputs outputs These parameters loaded user interface software automatically', 'content_type': 'text', 'score': 0.5311779177421433, 'meta': {'vector_id': '2929'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c2ef8a6a81a76b9b84de55da638d2d84'}>,\n",
       "  <Document: {'content': 'Method apparatus facilitating communication virtual machines A computerimplemented method apparatus virtual machine facilitating communication VMs The method facilitating communication first VM second VM includes allocating shared memory segment within memory physical machine mapping requested memory space addresses shared memory segments response memory space requests VMs providing requested memory space addresses A method communication first VM second VM includes requesting memory space response notification shared memory segment allocated obtaining requested memory space address mapped allocated shared memory segment accessing communication data shared memory segment according address The apparatus virtual machine executes steps methods', 'content_type': 'text', 'score': 0.5311626066326977, 'meta': {'vector_id': '2501'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a8a8e51de24d39f9ae17ddeca71303b'}>,\n",
       "  <Document: {'content': 'Information management tracking system IMTS An information management tracking system manages tracks artifact data relating development process artifact data including data relating development experiment parameters results products The system includes data management component process design environment retaining data relating process design A development tracking environment retains data relating process development including artifacts A back annotation environment receives process data provides development tracking environment The data management component arranged control process design environment development tracking environment back annotation environment that use data received stored therein accessed linked manner that use user obtain data environment view links between', 'content_type': 'text', 'score': 0.5286737698224112, 'meta': {'vector_id': '3188'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd26cc53dbe5aace08fac5a6515220bf6'}>,\n",
       "  <Document: {'content': 'Heterotopias cyberspace module In present invention users Internet share accumulate experiences referencing different uses experience data', 'content_type': 'text', 'score': 0.5283082893181298, 'meta': {'vector_id': '1839'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '808d28cac4e6a9a5a7704fa04c34f1da'}>,\n",
       "  <Document: {'content': 'High speed nonvolatile memory device using parallel writing among plurality interfaces Described high speed nonvolatile memory device technology includes controller coupled via interfaces sets nonvolatile storage separate flash memory chips separate regions single chip The controller includes logic processes write requests arbitrary size interleaving writes among interfaces including parallel writing among interfaces For example data may received via direct memory access DMA transfers The controller maintains information allow interleaved data reassembled correct relative locations read back DMA The high speed nonvolatile memory device thus provides hardware device software solution allows personal computer rapidly boot resume reduced power state hibernation The high speed nonvolatile memory device also may used data storage purposes caching file storage', 'content_type': 'text', 'score': 0.5282232177480873, 'meta': {'vector_id': '2585'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ad4f5a3fc838db6153e9de1beb6ea7bf'}>],\n",
       " 'root_node': 'Query',\n",
       " 'params': {},\n",
       " 'node_id': 'Generator'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pipe.run(\n",
    "    query=\"what is machine learning?\"\n",
    ")\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 7.09kB/s]\n",
      "c:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kchun\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 935kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.41MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 493/493 [00:00<00:00, 61.5kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [01:56<00:00, 3.76MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 3.46kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 568kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 586kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 492/492 [00:00<00:00, 123kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [01:55<00:00, 3.80MB/s] \n",
      "ML logging didn't work: name 'tracker' is not defined\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 4.60k/4.60k [00:00<00:00, 1.15MB/s]\n",
      "c:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\transformers\\models\\bart\\configuration_bart.py:179: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 14.8kB/s]\n",
      "Downloading (…)_tokenizer/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 727kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 20.9kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 6.41kB/s]\n",
      "Downloading (…)tokenizer/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 2.08MB/s]\n",
      "Downloading (…)tokenizer/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.08MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 772/772 [00:00<00:00, 193kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.06G/2.06G [09:13<00:00, 3.73MB/s]\n",
      "Some weights of the model checkpoint at facebook/rag-token-nq were not used when initializing RagTokenForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.weight', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RagTokenForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RagTokenForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RagTokenForGeneration were not initialized from the model checkpoint at facebook/rag-token-nq and are newly initialized: ['rag.generator.lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from crapstack.document_stores.faiss import FAISSDocumentStore\n",
    "from crapstack.haystack.nodes.retriever import DensePassageRetriever\n",
    "from crapstack.haystack.nodes.answer_generator import RAGenerator\n",
    "\n",
    "\n",
    "# Initialize FAISS document store.\n",
    "# Set `return_embedding` to `True`, so generator doesn't have to perform re-embedding\n",
    "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\", return_embedding=True)\n",
    "\n",
    "# Initialize DPR Retriever to encode documents, encode question and query documents\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    use_gpu=True,\n",
    "    embed_title=True,\n",
    ")\n",
    "\n",
    "# Initialize RAG Generator\n",
    "generator = RAGenerator(\n",
    "    model_name_or_path=\"facebook/rag-token-nq\",\n",
    "    use_gpu=True,\n",
    "    top_k=1,\n",
    "    max_length=200,\n",
    "    min_length=2,\n",
    "    embed_title=True,\n",
    "    num_beams=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:06, 1539.28it/s]            \n",
      "Updating Embedding:   0%|          | 0/3903 [16:52<?, ? docs/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m document_store\u001b[39m.\u001b[39mwrite_documents(documents)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Add documents embeddings to index\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m document_store\u001b[39m.\u001b[39;49mupdate_embeddings(retriever\u001b[39m=\u001b[39;49mretriever)\n",
      "File \u001b[1;32mc:\\Users\\kchun\\Desktop\\crapstack2\\crapstack\\document_stores\\faiss.py:362\u001b[0m, in \u001b[0;36mFAISSDocumentStore.update_embeddings\u001b[1;34m(self, retriever, index, update_existing_embeddings, filters, batch_size)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(\n\u001b[0;32m    359\u001b[0m     total\u001b[39m=\u001b[39mdocument_count, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m docs\u001b[39m\u001b[39m\"\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUpdating Embedding\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m ) \u001b[39mas\u001b[39;00m progress_bar:\n\u001b[0;32m    361\u001b[0m     \u001b[39mfor\u001b[39;00m document_batch \u001b[39min\u001b[39;00m batched_documents:\n\u001b[1;32m--> 362\u001b[0m         embeddings \u001b[39m=\u001b[39m retriever\u001b[39m.\u001b[39;49membed_documents(document_batch)\n\u001b[0;32m    363\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_embeddings_shape(\n\u001b[0;32m    364\u001b[0m             embeddings\u001b[39m=\u001b[39membeddings, num_documents\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(document_batch), embedding_dim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_dim\n\u001b[0;32m    365\u001b[0m         )\n\u001b[0;32m    367\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcosine\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kchun\\Desktop\\crapstack2\\crapstack\\haystack\\nodes\\retriever\\dense.py:578\u001b[0m, in \u001b[0;36mDensePassageRetriever.embed_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor\u001b[39m.\u001b[39mnum_hard_negatives \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    565\u001b[0m passages \u001b[39m=\u001b[39m [\n\u001b[0;32m    566\u001b[0m     {\n\u001b[0;32m    567\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpassages\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents\n\u001b[0;32m    577\u001b[0m ]\n\u001b[1;32m--> 578\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_predictions(passages)[\u001b[39m\"\u001b[39m\u001b[39mpassages\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    579\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\kchun\\Desktop\\crapstack2\\crapstack\\haystack\\nodes\\retriever\\dense.py:518\u001b[0m, in \u001b[0;36mDensePassageRetriever._get_predictions\u001b[1;34m(self, dicts)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[39m# get logits\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode():\n\u001b[1;32m--> 518\u001b[0m     query_embeddings, passage_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(\n\u001b[0;32m    519\u001b[0m         query_input_ids\u001b[39m=\u001b[39;49mbatch\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mquery_input_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    520\u001b[0m         query_segment_ids\u001b[39m=\u001b[39;49mbatch\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mquery_segment_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    521\u001b[0m         query_attention_mask\u001b[39m=\u001b[39;49mbatch\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mquery_attention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    522\u001b[0m         passage_input_ids\u001b[39m=\u001b[39;49mbatch\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mpassage_input_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    523\u001b[0m         passage_segment_ids\u001b[39m=\u001b[39;49mbatch\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mpassage_segment_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    524\u001b[0m         passage_attention_mask\u001b[39m=\u001b[39;49mbatch\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mpassage_attention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    525\u001b[0m     )[\u001b[39m0\u001b[39m]\n\u001b[0;32m    526\u001b[0m     \u001b[39mif\u001b[39;00m query_embeddings \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    527\u001b[0m         query_embeddings_batched\u001b[39m.\u001b[39mappend(query_embeddings\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[1;32mc:\\Users\\kchun\\Desktop\\crapstack2\\crapstack\\haystack\\modeling\\model\\biadaptive_model.py:286\u001b[0m, in \u001b[0;36mBiAdaptiveModel.forward\u001b[1;34m(self, query_input_ids, query_segment_ids, query_attention_mask, passage_input_ids, passage_segment_ids, passage_attention_mask)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39mPush data through the whole model and returns logits. The data will propagate through\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39mthe first language model and second language model based on the tensor names and both the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39m:return: All logits as torch.tensor or multiple tensors.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[39m# Run forward pass of both language models\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_lm(\n\u001b[0;32m    287\u001b[0m     query_input_ids\u001b[39m=\u001b[39;49mquery_input_ids,\n\u001b[0;32m    288\u001b[0m     query_segment_ids\u001b[39m=\u001b[39;49mquery_segment_ids,\n\u001b[0;32m    289\u001b[0m     query_attention_mask\u001b[39m=\u001b[39;49mquery_attention_mask,\n\u001b[0;32m    290\u001b[0m     passage_input_ids\u001b[39m=\u001b[39;49mpassage_input_ids,\n\u001b[0;32m    291\u001b[0m     passage_segment_ids\u001b[39m=\u001b[39;49mpassage_segment_ids,\n\u001b[0;32m    292\u001b[0m     passage_attention_mask\u001b[39m=\u001b[39;49mpassage_attention_mask,\n\u001b[0;32m    293\u001b[0m )\n\u001b[0;32m    295\u001b[0m \u001b[39m# Run forward pass of (multiple) prediction heads using the output from above\u001b[39;00m\n\u001b[0;32m    296\u001b[0m all_logits \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\Desktop\\crapstack2\\crapstack\\haystack\\modeling\\model\\biadaptive_model.py:357\u001b[0m, in \u001b[0;36mBiAdaptiveModel.forward_lm\u001b[1;34m(self, query_input_ids, query_segment_ids, query_attention_mask, passage_input_ids, passage_segment_ids, passage_attention_mask)\u001b[0m\n\u001b[0;32m    354\u001b[0m     passage_attention_mask \u001b[39m=\u001b[39m passage_attention_mask\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, max_seq_len)\n\u001b[0;32m    355\u001b[0m     passage_segment_ids \u001b[39m=\u001b[39m passage_segment_ids\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, max_seq_len)\n\u001b[1;32m--> 357\u001b[0m     pooled_output2, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlanguage_model2(\n\u001b[0;32m    358\u001b[0m         input_ids\u001b[39m=\u001b[39;49mpassage_input_ids, segment_ids\u001b[39m=\u001b[39;49mpassage_segment_ids, attention_mask\u001b[39m=\u001b[39;49mpassage_attention_mask\n\u001b[0;32m    359\u001b[0m     )\n\u001b[0;32m    360\u001b[0m     pooled_output[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m pooled_output2\n\u001b[0;32m    362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\Desktop\\crapstack2\\crapstack\\haystack\\modeling\\model\\language_model.py:719\u001b[0m, in \u001b[0;36mDPREncoder.forward\u001b[1;34m(self, input_ids, attention_mask, segment_ids, output_hidden_states, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[39mPerform the forward pass of the DPR encoder model.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m:return: Embeddings for each token in the input sequence.\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    715\u001b[0m output_hidden_states \u001b[39m=\u001b[39m (\n\u001b[0;32m    716\u001b[0m     output_hidden_states \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39moutput_hidden_states\n\u001b[0;32m    717\u001b[0m )\n\u001b[1;32m--> 719\u001b[0m model_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[0;32m    720\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    721\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49msegment_ids,\n\u001b[0;32m    722\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    723\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    724\u001b[0m     output_attentions\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    725\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    726\u001b[0m )\n\u001b[0;32m    728\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    729\u001b[0m     \u001b[39mreturn\u001b[39;00m model_output\u001b[39m.\u001b[39mpooler_output, model_output\u001b[39m.\u001b[39mhidden_states\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\transformers\\models\\dpr\\modeling_dpr.py:508\u001b[0m, in \u001b[0;36mDPRContextEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[39mif\u001b[39;00m token_type_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m--> 508\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx_encoder(\n\u001b[0;32m    509\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    510\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    511\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m    512\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    513\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    514\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    515\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    516\u001b[0m )\n\u001b[0;32m    518\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[0;32m    519\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\transformers\\models\\dpr\\modeling_dpr.py:197\u001b[0m, in \u001b[0;36mDPREncoder.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    188\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    189\u001b[0m     input_ids: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    195\u001b[0m     return_dict: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    196\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[BaseModelOutputWithPooling, Tuple[Tensor, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]:\n\u001b[1;32m--> 197\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert_model(\n\u001b[0;32m    198\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    199\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    200\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m    201\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    202\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    203\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    204\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    205\u001b[0m     )\n\u001b[0;32m    206\u001b[0m     sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    207\u001b[0m     pooled_output \u001b[39m=\u001b[39m sequence_output[:, \u001b[39m0\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1021\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1012\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1014\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1015\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1016\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1020\u001b[0m )\n\u001b[1;32m-> 1021\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1022\u001b[0m     embedding_output,\n\u001b[0;32m   1023\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1024\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1025\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1026\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1027\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1028\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1029\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1030\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1031\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1032\u001b[0m )\n\u001b[0;32m   1033\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1034\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[0;32m    612\u001b[0m         attention_mask,\n\u001b[0;32m    613\u001b[0m         layer_head_mask,\n\u001b[0;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    616\u001b[0m         past_key_value,\n\u001b[0;32m    617\u001b[0m         output_attentions,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:496\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    485\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    486\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    493\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    494\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    495\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    497\u001b[0m         hidden_states,\n\u001b[0;32m    498\u001b[0m         attention_mask,\n\u001b[0;32m    499\u001b[0m         head_mask,\n\u001b[0;32m    500\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    501\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    502\u001b[0m     )\n\u001b[0;32m    503\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    505\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:426\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    417\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    418\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    424\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    425\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 426\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    427\u001b[0m         hidden_states,\n\u001b[0;32m    428\u001b[0m         attention_mask,\n\u001b[0;32m    429\u001b[0m         head_mask,\n\u001b[0;32m    430\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    431\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    432\u001b[0m         past_key_value,\n\u001b[0;32m    433\u001b[0m         output_attentions,\n\u001b[0;32m    434\u001b[0m     )\n\u001b[0;32m    435\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    436\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:354\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    351\u001b[0m     attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m+\u001b[39m attention_mask\n\u001b[0;32m    353\u001b[0m \u001b[39m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m attention_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(attention_scores, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    356\u001b[0m \u001b[39m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[39m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m attention_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[1;32mc:\\Users\\kchun\\anaconda3\\envs\\crapstack3\\lib\\site-packages\\torch\\nn\\functional.py:1841\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1839\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1840\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1841\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   1842\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1843\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Delete existing documents in documents store\n",
    "document_store.delete_documents()\n",
    "\n",
    "# Write documents to document store\n",
    "document_store.write_documents(documents)\n",
    "\n",
    "# Add documents embeddings to index\n",
    "document_store.update_embeddings(retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
